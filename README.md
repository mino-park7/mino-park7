# **Minho Park**

### **ML Engineering Lead | LLM Inference Optimization | MLOps**

### **üëã About Me**

Hello! I'm Minho Park, an ML Engineering Lead who architects and leads the development of scalable, end-to-end LLM Inference Hardware SDKs. I specialize in efficient model serving and operational optimization, currently driving the development of a vLLM-based framework and a Kubernetes-native SDK. I am skilled in managing and automating the full software development lifecycle and have extensive experience in model optimization, MLOps, and deep learning research at an AI semiconductor company.

* üìß **Email**: minho.park2115@gmail.com  
* üíº **LinkedIn**: linkedin.com/in/your-profile  
* üíª **GitHub**: github.com/your-username

### **üöÄ Career Summary**

* **ML Engineering Lead** at **HyperAccel** (Dec 2024 ~ Present)  
* **Data Scientist** at **PwC Consulting** (Jun 2024 ~ Dec 2024)  
* **ML Engineer** at **Neubla Korea Corporation** (Jun 2022 ~ May 2024)  
* **ML Engineer** at **Samsung Electronics** (Feb 2021 ~ May 2022)  
* **Tech Lead** at **Tmax AI** (Feb 2017 ~ Jan 2021)

### **üõ†Ô∏è Core Competencies**

**Leadership & Platform Architecture**

* **Team Leadership & Management**: Leading ML engineering teams to develop and deliver cutting-edge LLM Inference Engine.  
* **LLM Inference Engine Architecture**: Architecting and spearheading the development of LLM Inference Engine (vLLM Hardware PlugIn), and Kubernetes Device PlugIn for HyperAccel LPU.  
* **DevOps & MLOps Strategy**: Managing and automating the entire software development environment to maximize efficiency from development to operation.  
* **Cross-functional Collaboration**: Experienced in working closely with hardware design and development teams to co-create algorithms, design architectures, and patents.

**Technical Expertise**

* **LLM Inference Optimization**:  
  * Attention Mechanisms (Paged Attention, Flash Attention)  
  * Kernel Fusion  
  * Quantization (AWQ, GPTQ, ...)  
  * Parallelisms (Tensor, Pipeline)  
  * Speculative Decoding  
* **Distributed & MLOps Infrastructure**:  
  * Kubernetes-based ML Infrastructure  
  * Distributed LLM Inference (Tensor/Data/Pipeline Parallelism)

### **üíª Skills**

* **Languages**: Python, C++, CUDA  
* **ML Packages**: vLLM, PyTorch, Transformers, Scikit-Learn, Pandas, SciPy, NumPy  
* **OS/Cloud**: AWS, GCP, Kubernetes, Linux, Docker  
* **Software Engineering**: Git, Github, Github Actions, Jira, Confluence

### **üéì Education**

* **M.S. in Nuclear Engineering**, Seoul National University (Mar 2015 ~ Feb 2017)  
* **B.S. in Nuclear Engineering**, Seoul National University (Mar 2011 ~ Feb 2015)

### **üìú Publications**

* Ko, J., Bae, J., **Park, M.**, Ko, Y., Kim, B. (2023). *Computational approach for plasma process optimization combined with deep learning model*. Journal of Physics D: Applied Physics.  
* **Park, M.**, Na, Y. S., Seo, J., Kim, M., & Kim, K. (2017). *Effect of electron cyclotron beam width to neoclassical tearing mode stabilization by minimum seeking control in ITER*. Nuclear Fusion.

### **üèÜ Awards**

* **Outstanding Educator Award**, Samsung DS Design University (AI System) - Dec 2021  
* **Annual Technology Innovation Award**, Tmax Data - Jan 2019

<p align="right">Last Updated: Oct 1, 2025</p>